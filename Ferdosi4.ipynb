{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ferdosi4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/farahbakhsh3/X1/blob/master/Ferdosi4.ipynb)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CBfckJ7Rj_UQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !wget https://www.dropbox.com/s/laax0sxqzzlddtq/ferdosi.txt\n",
        "# !wget https://www.dropbox.com/s/ripsc7hfc0nihy5/test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fhg9DmgqjwML",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        " \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout\n",
        "from keras.layers import LSTM, GRU, CuDNNGRU, CuDNNLSTM \n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aIIF4NrDjwMf",
        "outputId": "face67a9-93b9-41a2-a73d-f2591ac4f3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "path = './ferdosi.txt'\n",
        "with open(path, encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "\n",
        "beits = texts.split('\\n')\n",
        "# texts = texts.split('\\n')\n",
        "texts = texts.replace('\\n', 'ــ ')\n",
        "texts = texts.split(' ')\n",
        "# texts = text_to_word_sequence(texts)\n",
        "\n",
        "print('corpus length:', len(texts))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 561804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HiCtlwDejwMp",
        "outputId": "e99c1416-043d-4460-9fb3-e9d89fdd85e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_length = 8\n",
        "embeding_dim = 100\n",
        "step = 5\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "sequences = [sequences[i][0] for i in range(len(sequences)-1)]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "len_of_words = len(word_index)\n",
        "word2idx = word_index\n",
        "idx2word = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# paded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "# paded_sequences = [paded_sequences[i][0] for i in range(len(paded_sequences)-1)]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21963 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6fitDBtHjwMz",
        "outputId": "1128d133-3533-466d-8829-09d4ab55e8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sentences = []\n",
        "next_word = []\n",
        "for i in range(0, len(sequences) - max_length, step):\n",
        "    sentences.append(sequences[i: i + max_length])\n",
        "    next_word.append(sequences[i + max_length])\n",
        "print('nb sentences:', len(sentences))\n",
        "print('nb next_word:', len(next_word))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sentences: 112359\n",
            "nb next_word: 112359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qoR78UsYjwNG",
        "outputId": "a000107e-db88-461d-85b1-326fbbce0c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "for ii in range(3):\n",
        "\n",
        "    print(sentences[ii])\n",
        "    print([idx2word.get(i, '') for i in sentences[ii]])\n",
        "\n",
        "    print(next_word[ii])\n",
        "    print(idx2word[next_word[ii]])\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 95, 339, 103, 1, 368, 344, 705]\n",
            "['به', 'نام', 'خداوند', 'جان', 'و', 'خردــ', 'کزین', 'برتر']\n",
            "215\n",
            "اندیشه\n",
            "[368, 344, 705, 215, 6225, 339, 95, 1]\n",
            "['خردــ', 'کزین', 'برتر', 'اندیشه', 'برنگذردــ', 'خداوند', 'نام', 'و']\n",
            "339\n",
            "خداوند\n",
            "[339, 95, 1, 339, 182, 339, 685, 282]\n",
            "['خداوند', 'نام', 'و', 'خداوند', 'جایــ', 'خداوند', 'روزی', 'ده']\n",
            "488\n",
            "رهنمایــ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j5i6q3Y_jwN8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array(sentences)\n",
        "y = np.array(next_word)\n",
        "# y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "es4d-YfljwOU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "#     if epoch % 10 != 0:\n",
        "#         return\n",
        "    \n",
        "    start_index = random.randint(0, len(beits) - 1)\n",
        "    for diversity in [1.0]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        sentence = beits[start_index] + 'ــ'\n",
        "        print(sentence)\n",
        "        generated = sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        for i in range(max_length * 10):\n",
        "            x_pred = np.zeros((1, max_length), dtype=int)\n",
        "            for t, word in enumerate(sentence.split(' ')[:max_length]):\n",
        "                try:\n",
        "#                     print(t, word)\n",
        "                    x_pred[0, t] = word2idx[word]\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            pred_id = sample(preds, diversity)\n",
        "            next_word = idx2word[pred_id]\n",
        "\n",
        "            generated = generated + ' ' + next_word\n",
        "            sentence = ' '.join(sentence.split(' ')[1:])\n",
        "            sentence = sentence + ' ' + next_word\n",
        "\n",
        "        print(generated.replace('ــ', '\\n'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ocv8HVeAjwOq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtwNGY_FGHrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4865fb93-f353-4f1c-9824-627bf703949c"
      },
      "cell_type": "code",
      "source": [
        "# model = models.Sequential()\n",
        "# model.add(layers.Embedding(len(word_index), 100))\n",
        "# model.add(layers.LSTM(128))\n",
        "# model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len_of_words, embeding_dim, input_length=max_length))\n",
        "if tf.test.is_gpu_available():\n",
        "#     model.add(CuDNNGRU(512, return_sequences=True))\n",
        "    model.add(CuDNNGRU(256))\n",
        "else:\n",
        "    model.add(GRU(256))\n",
        "model.add(Dense(len_of_words, activation='softmax'))\n",
        " \n",
        "model.compile(optimizer=RMSprop(0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "print(model.summary())\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 8, 100)            2196300   \n",
            "_________________________________________________________________\n",
            "cu_dnngru_14 (CuDNNGRU)      (None, 256)               274944    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 21963)             5644491   \n",
            "=================================================================\n",
            "Total params: 8,115,735\n",
            "Trainable params: 8,115,735\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UDNdT_VEjwO7",
        "outputId": "444354d8-fb3b-4f90-ba61-6d3e66749ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(x=x, y=y, epochs=150, batch_size=128, callbacks=[print_callback], validation_split=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 101123 samples, validate on 11236 samples\n",
            "Epoch 1/150\n",
            "101123/101123 [==============================] - 22s 218us/step - loss: 7.1685 - acc: 0.0804 - val_loss: nan - val_acc: 0.0933\n",
            "----- diversity: 1.0\n",
            "دگر هرچ بودش به درویش دادــ\n",
            "----- Generating with seed: \"دگر هرچ بودش به درویش دادــ\"\n",
            "دگر هرچ بودش به درویش داد\n",
            " بدو اندر گردان به به نیز\n",
            " سواران و آمدند\n",
            " بران و یل همانا نخوانمت و سوی بباید اکنون که اندر و بزد بد خویشتن نازی و و همه چنین برآشفت و تا تخت\n",
            " سخنها و رخ و که به و که کار\n",
            " پدر\n",
            " به تارک کن بد چشم\n",
            " چون یکی ره بیامد و سرود\n",
            " بر روشنروان\n",
            " همیشه بر داند اندرین ببند\n",
            " به و کین\n",
            " سپاه سر و گرگ و از ز نیاید یکی دژ شاه همه و چنان و چنین\n",
            "Epoch 2/150\n",
            "101123/101123 [==============================] - 21s 206us/step - loss: 6.6962 - acc: 0.1195 - val_loss: nan - val_acc: 0.1000\n",
            "----- diversity: 1.0\n",
            "وگر تیغ زن نامداری سترگــ\n",
            "----- Generating with seed: \"وگر تیغ زن نامداری سترگــ\"\n",
            "وگر تیغ زن نامداری سترگ\n",
            " بود\n",
            " بود\n",
            " بود\n",
            " شتاب\n",
            " بدو که برین به گودرز زان شد آفرین چنین مردم زبان کز به همی از و جهان را به برادر بید بنشست سپهر بفرمود چو یار به مردم از و شاد یک و بدین که لشکر اکنون چو چو وگر روشن و به تیر\n",
            " همه یکی خواند\n",
            " مشک و و ز از ما پیروز نه سواران از با تا نباشد پس همی و و نیک به جنگ بدین وزین افراسیاب\n",
            " و رومی چو شهر دو و\n",
            "Epoch 3/150\n",
            "101123/101123 [==============================] - 21s 206us/step - loss: 6.7473 - acc: 0.1423 - val_loss: nan - val_acc: 0.1009\n",
            "----- diversity: 1.0\n",
            "برفتند یارانش با او بهمــ\n",
            "----- Generating with seed: \"برفتند یارانش با او بهمــ\"\n",
            "برفتند یارانش با او بهم\n",
            " بودی چو دل اندر جهان و یکی به و روی آن از من گیتی ز دست برآمد اندازه دیو بند\n",
            " میان\n",
            " شد گرد تخت بران برو اندرون و پر زال مردان فرخ بر یکی پند هرانکس گاه اندر گفت\n",
            " بد دو گیرد گفت\n",
            " گرد\n",
            " خواهد سه جفت\n",
            " بود\n",
            " اندازه تیر\n",
            " نزدیک ز میان بر و زمین از خروشی بدان بد پای ز نو نبیند بر پیش ورا به آمد شد زد زمین بر بر تا بر گشتند اندرون تیر نو\n",
            "Epoch 4/150\n",
            "101123/101123 [==============================] - 21s 207us/step - loss: 6.6496 - acc: 0.1626 - val_loss: nan - val_acc: 0.0994\n",
            "----- diversity: 1.0\n",
            "دگر باد و آتش همان آب پاکــ\n",
            "----- Generating with seed: \"دگر باد و آتش همان آب پاکــ\"\n",
            "دگر باد و آتش همان آب پاک\n",
            " پیش گاو همچو با شده به اندر یکی سوار\n",
            " پاسخ یکی سراسر یاد\n",
            " چون سر نهفت\n",
            " ز رمه\n",
            " با آمد و ازان شیر\n",
            " را با و و و دراز\n",
            " زبان بسیار سرای ازو برو همه تو ز بپیران شد و و و ای همیشه گشت\n",
            " بدید\n",
            " بدست\n",
            " هر که بود\n",
            " باید به نیست\n",
            " بر و جهان ترا دل دراز\n",
            " بر و تو کرد و شیر\n",
            " خاور ز پس و او وز بزرگان در گشت اوی\n",
            " بدست\n",
            " گشته بسیار نیست\n",
            " کسی\n",
            "Epoch 5/150\n",
            "101123/101123 [==============================] - 21s 207us/step - loss: 6.5709 - acc: 0.1755 - val_loss: nan - val_acc: 0.0955\n",
            "----- diversity: 1.0\n",
            "بفرمود تا پیش او شد دبیرــ\n",
            "----- Generating with seed: \"بفرمود تا پیش او شد دبیرــ\"\n",
            "بفرمود تا پیش او شد دبیر\n",
            " ز طوس\n",
            " انجمن\n",
            " درنگ\n",
            " نخچیر و برآورد گرفته با بسی دشت\n",
            " عاج\n",
            " را سوی جنگ\n",
            " به چنین دل تهمتن کند برو جهاندار که یک سپهدار دلیران به آب ز روشن زمین خروشی چو یکسره\n",
            " این بود همان سر روان\n",
            " سرش گردنکشان\n",
            " کین بدید\n",
            " گر گرفت\n",
            " ماند از زره روشن بر چو مرا بود\n",
            " کسی همی بود\n",
            " چیز کزین و جهان همی ازین داد جهاندار مبادا زین سرافراز کسری بیگانه و باید نزد من\n",
            " خیره جهاندار هر دید نزدیک خوب سر\n",
            "Epoch 6/150\n",
            "101123/101123 [==============================] - 21s 207us/step - loss: 6.5024 - acc: 0.1872 - val_loss: nan - val_acc: 0.0934\n",
            "----- diversity: 1.0\n",
            "نه آن زین نه این زان بود بینیازــ\n",
            "----- Generating with seed: \"نه آن زین نه این زان بود بینیازــ\"\n",
            "نه آن زین نه این زان بود بینیاز\n",
            " فراوان جان برفتند زو به زد بسته و آب سپه و پاک\n",
            " سیاوش چو زو گر سپه گردد گر پاک از جهان\n",
            " ازو بسته بر شیر از سوی خون\n",
            " بشد هیچ رزم خرد\n",
            " شود پیش او فرمان خود را بباید مکن\n",
            " همه بخردان\n",
            " آن باره را دور\n",
            " به نیست\n",
            " یکی گردش سخن\n",
            " برین تا که گاه رزم مرد خسته زمان دراز\n",
            " بفرمود پس دیگر بران پاک آورد زره کشید\n",
            " دلاور شب تو جای کارزار\n",
            " چو شیر پدر خاک\n",
            " به روی\n",
            "\n",
            "Epoch 7/150\n",
            " 95232/101123 [===========================>..] - ETA: 1s - loss: 6.4462 - acc: 0.1959"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7BdooMAYjwPP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lLqOA0YojwPY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
        "plt.plot(epochs, acc_values, 'ro', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
        "plt.title('Training & Validation Loss - acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss - acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5J8M0pHmCn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}