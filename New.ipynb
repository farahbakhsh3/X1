{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/farahbakhsh3/X1/blob/master/New.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "q3OYB0SGSl1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install unrar\n",
        "!wget https://www.dropbox.com/s/rl6nx5e5h0ff4ub/lesson9.rar\n",
        "!unrar x -r lesson9.rar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_QaXjQ_ZvSue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "02f31870-86cc-4c6c-a734-c1eb54480df4"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        " \n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        " \n",
        " \n",
        "# load data (raw text file)\n",
        "################################################################################\n",
        "################################################################################\n",
        " \n",
        "path = './lesson9/data/ferdosi.txt'\n",
        "with open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        " \n",
        "# create two dictionaries: (index to id) & (id to index)\n",
        "################################################################################\n",
        "################################################################################\n",
        " \n",
        "chars = sorted(list(set(text)))\n",
        "len_of_char = len(chars)\n",
        "print('total chars:', len(chars))\n",
        "char2idx = dict((c, i) for i, c in enumerate(chars))\n",
        "idx2char = dict((i, c) for i, c in enumerate(chars))\n",
        " \n",
        "# convert each character to an unique id\n",
        "################################################################################\n",
        "################################################################################\n",
        " \n",
        "max_length = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - max_length, step):\n",
        "    sentences.append(text[i: i + max_length])\n",
        "    next_chars.append(text[i + max_length])\n",
        "print('nb sequences:', len(sentences))\n",
        " \n",
        "# create proper vector for training model\n",
        "################################################################################\n",
        "################################################################################\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), max_length, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences)))\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char2idx[char]] = 1\n",
        "    y[i] = char2idx[next_chars[i]]\n",
        " \n",
        " \n",
        "# two helper functions to print generated text at the end of each epoch\n",
        "################################################################################\n",
        "################################################################################\n",
        "def on_epoch_end(epoch, _):\n",
        "    if epoch % 10 != 0:\n",
        "        return\n",
        "    \n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        " \n",
        "    start_index = random.randint(0, len(text) - max_length - 1)\n",
        "    for diversity in [1.0]:\n",
        "        print('----- diversity:', diversity)\n",
        " \n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + max_length]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        " \n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, max_length, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char2idx[char]] = 1.\n",
        " \n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            pred_id = sample(preds, diversity)\n",
        "            next_char = idx2char[pred_id]\n",
        " \n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        " \n",
        "        print(generated)\n",
        " \n",
        " \n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        " \n",
        " \n",
        "# Define simple GRU model for generating text\n",
        "# In case of using CPU replace the CuDNNGRU with GRU\n",
        "################################################################################\n",
        "################################################################################\n",
        " \n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.CuDNNGRU(256, input_shape=(max_length, len_of_char)))\n",
        "# model.add(keras.layers.GRU(256, input_shape=(max_length, len_of_char)))\n",
        "model.add(keras.layers.Dense(len_of_char, activation='softmax'))\n",
        " \n",
        "# Create graph and train the model for 60 epoch\n",
        "################################################################################\n",
        "################################################################################\n",
        " \n",
        "model.compile(optimizer=keras.optimizers.RMSprop(0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "print(model.summary())\n",
        "print_callback = keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.fit(x=x, y=y, epochs=60, batch_size=128, callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 2553468\n",
            "total chars: 47\n",
            "nb sequences: 851143\n",
            "Vectorization...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 256)               234240    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 47)                12079     \n",
            "=================================================================\n",
            "Total params: 246,319\n",
            "Trainable params: 246,319\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/60\n",
            "850688/851143 [============================>.] - ETA: 0s - loss: 1.8484 - acc: 0.4630\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"یزدان نیکی دهش کرد یاد\n",
            "بفرمود کان را که \"\n",
            "یزدان نیکی دهش کرد یاد\n",
            "بفرمود کان را که دارگفت\n",
            "چو دادن و چندان گسلاستست\n",
            "بدو پیز شد بر نیازور دشمن کاست شاد\n",
            "که چون روی نده انکمانان چنین\n",
            "پسیرام شاهگرد زندی به یزدانشوی\n",
            "ز کاران بگفت او فریبرز گون\n",
            "بدینی گرین آودی پرندی\n",
            "به مغز برفتار و ز کیان هرگزن\n",
            "نه اسر مراگر سود هر سوارست\n",
            "گر ازدش که روز چشم کار جنگ\n",
            "بیاید بدیدن بکاید ز هو نامهان\n",
            "کجا گفت کین گشت زین بجای\n",
            "پسر دز گنه نیکیم با جنگی\n",
            "برادر بی از در و تن بایگاه و دژم\n",
            "ورایم فر تو گرز گرز بوا تاچه\n",
            "851143/851143 [==============================] - 109s 128us/step - loss: 1.8483 - acc: 0.4630\n",
            "Epoch 2/60\n",
            "851143/851143 [==============================] - 107s 126us/step - loss: 1.8066 - acc: 0.4691\n",
            "Epoch 3/60\n",
            "851143/851143 [==============================] - 107s 126us/step - loss: 2.7558 - acc: 0.2484\n",
            "Epoch 4/60\n",
            "173312/851143 [=====>........................] - ETA: 1:25 - loss: 2.7613 - acc: 0.2316"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oicrf_z7v5hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}